{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:3.75em;color:purple; font-style:bold\"><br>\n",
    "Pandas</p><br>\n",
    "\n",
    "*pandas* is a Python library for data analysis. It offers a number of data exploration, cleaning and transformation operations that are critical in working with data in Python. \n",
    "\n",
    "*pandas* builds upon *numpy* and *scipy* providing easy-to-use data structures and data manipulation functions with integrated indexing.\n",
    "\n",
    "The main data structures *pandas* provides are *Series* and *DataFrames*. After a brief introduction to these two data structures and data ingestion, the key features of *pandas* this notebook covers are:\n",
    "* Generating descriptive statistics on data\n",
    "* Data cleaning using built in pandas functions\n",
    "* Frequent data operations for subsetting, filtering, insertion, deletion and aggregation of data\n",
    "* Merging multiple datasets using dataframes\n",
    "* Working with timestamps and time-series data\n",
    "\n",
    "**Additional Recommended Resources:**\n",
    "* *pandas* Documentation: http://pandas.pydata.org/pandas-docs/stable/\n",
    "* *Python for Data Analysis* by Wes McKinney\n",
    "* *Python Data Science Handbook* by Jake VanderPlas\n",
    "\n",
    "Let's get started with our first *pandas* notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.75em;color:#2462C0; font-style:bold\"><br>\n",
    "\n",
    "Import Libraries\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.75em;color:#2462C0; font-style:bold\">\n",
    "Introduction to pandas Data Structures</p>\n",
    "<br>\n",
    "*pandas* has two main data structures it uses, namely, *Series* and *DataFrames*. \n",
    "\n",
    "<p style=\"font-family: Arial; font-size:1.75em;color:#2462C0; font-style:bold\">\n",
    "pandas Series</p>\n",
    "\n",
    "*pandas Series* is a one-dimensional labeled array. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(data=[100, 200, 300, 400, 500], index=['tom', 'bob', 'nancy', 'dan', 'eric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser['nancy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser[[4, 3, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'bob' in ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.75em;color:#2462C0; font-style:bold\">\n",
    "pandas DataFrame</p>\n",
    "\n",
    "*pandas DataFrame* is a 2-dimensional labeled data structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.25em;color:#2462C0; font-style:bold\">\n",
    "Create DataFrame from dictionary of Python Series</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'one' : pd.Series([100., 200., 300.], index=['apple', 'ball', 'clock']),\n",
    "     'two' : pd.Series([111., 222., 333., 4444.], index=['apple', 'ball', 'cerill', 'dancy'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(d)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(d, index=['dancy', 'ball', 'apple'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(d, index=['dancy', 'ball', 'apple'], columns=['two', 'five'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.25em;color:#2462C0; font-style:bold\">\n",
    "Create DataFrame from list of Python dictionaries</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{'alex': 1, 'joe': 2}, {'ema': 5, 'dora': 10, 'alice': 20}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data, index=['orange', 'red'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data, columns=['joe', 'dora','alice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.25em;color:#2462C0; font-style:bold\">\n",
    "Basic DataFrame operations</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing by a column returns that column as a Series\n",
    "\n",
    "df['one']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar to dictionaries, when indexing DataFrames by a new key (or column), a new column is created in the DataFrame\n",
    "\n",
    "df['three'] = df['one'] * df['two']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['flag'] = df['one'] > 250\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .pop method returns the popped column as a panda Series - can store in a variable\n",
    "\n",
    "three = df.pop('three')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del deletes specified column without returning anything\n",
    "\n",
    "del df['two']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can insert new columns by specified location using .insert method. arguments: (loc, column name, value)\n",
    "\n",
    "df.insert(2, 'copy_of_one', df['one'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when copying new columns in a DataFrame, you can also specify how much data you want from the source copied by slicing\n",
    "# the data using indexing. values not copied show as NaN\n",
    "\n",
    "df['one_upper_half'] = df['one'][:2]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.75em;color:#2462C0; font-style:bold\">\n",
    "Case Study: Movie Data Analysis</p>\n",
    "<br>This notebook uses a dataset from the MovieLens website. We will describe the dataset further as we explore with it using *pandas*. \n",
    "\n",
    "## Download the Dataset\n",
    "\n",
    "### Please note that **you will need to download the dataset**. \n",
    "\n",
    "Although the video for this notebook says that the data is in your folder, the folder turned out to be too large to fit on the edX platform due to size constraints.\n",
    "\n",
    "Here are the links to the data source and location:\n",
    "* **Data Source:** MovieLens web site (filename: ml-20m.zip)\n",
    "* **Location:** https://grouplens.org/datasets/movielens/\n",
    "\n",
    "Once the download completes, please make sure the data files are in a directory called **movielens** in your **Week-4-pandas** folder. \n",
    "\n",
    "Let us look at the files in this dataset using the UNIX command ls.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Adjust the name of the folder to match your local directory\n",
    "\n",
    "!ls ./movielens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ./movielens/movies.csv\n",
    "\n",
    "# Note the csv has labels for the data columns (movieId,title,genres) - if these weren't there, the data would be indexed\n",
    "# numerically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can check the line count of the csv file by piping into the wc filter and specifying -l for lines -> this is the number\n",
    "# of movies in our movie database\n",
    "\n",
    "!cat ./movielens/movies.csv | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check quickly if the other csv files contain data and to see how it's formatted we can use the unix head command\n",
    "\n",
    "!head -n5 ./movielens/links.csv\n",
    "print()\n",
    "!head -n5 ./movielens/genome-scores.csv\n",
    "print()\n",
    "!head -n5 ./movielens/genome-tags.csv\n",
    "print()\n",
    "!head -n5 ./movielens/ratings.csv\n",
    "print()\n",
    "!head -n5 ./movielens/tags.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we know the data is good - we can start loading it in to DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.75em;color:#2462C0; font-style:bold\">\n",
    "Use Pandas to Read the Dataset<br>\n",
    "</p>\n",
    "<br>\n",
    "In this notebook, we will be using three CSV files:\n",
    "* **ratings.csv :** *userId*,*movieId*,*rating*, *timestamp*\n",
    "* **tags.csv :** *userId*,*movieId*, *tag*, *timestamp*\n",
    "* **movies.csv :** *movieId*, *title*, *genres* <br>\n",
    "\n",
    "Using the *read_csv* function in pandas, we will ingest these three files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below, movies is a pandas DataFrame type object. using the .read_csv method we pass in arguments for file and seperator\n",
    "\n",
    "movies = pd.read_csv('./movielens/movies.csv', sep=',')\n",
    "print(type(movies))\n",
    "\n",
    "# .head is a DataFrame method that displays the first 5 rows by default. We can pass in a different number to get back\n",
    "# a different number of rows of data, e.g. .head(15)\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamps represent seconds since midnight Coordinated Universal Time (UTC) of January 1, 1970\n",
    "\n",
    "tags = pd.read_csv('./movielens/tags.csv', sep=',')\n",
    "tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read further below on section \"Parsing Timestampes\" to learn more on timestamps\n",
    "\n",
    "ratings = pd.read_csv('./movielens/ratings.csv', sep=',', parse_dates=['timestamp'])\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For current analysis, we will remove timestamp (we will come back to it!)\n",
    "\n",
    "del ratings['timestamp']\n",
    "del tags['timestamp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:2em;color:#2467C0\">Data Structures </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:1.5em;color:#2467C0\">Series</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract 0th row: notice that it is infact a Series\n",
    "# .iloc method is used to extract a given row in a DataFrame - returns a Series\n",
    "\n",
    "row_0 = tags.iloc[0]\n",
    "type(row_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(row_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the Series method .index  returns the index labels for the series\n",
    "\n",
    "row_0.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing the series by the index label returns the value for that label\n",
    "\n",
    "row_0['userId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rating is not an index label for the Series, so below returns False\n",
    "\n",
    "'rating' in row_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .name method returns the name of the returned Series - this can be renamed using the .rename method as below\n",
    "\n",
    "row_0.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_0 = row_0.rename('first_row')\n",
    "row_0.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:1.5em;color:#2467C0\">DataFrames </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .index in a DataFrame returns information on the rows (index data)\n",
    "\n",
    "tags.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .columns method returns information on the column headers\n",
    "\n",
    "tags.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below extracts rows 0, 11, 2000 from the DataFrame using the .iloc method and indexing accordingly - returns an array\n",
    "# containing the expected values\n",
    "\n",
    "tags.iloc[ [0,11,2000] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:2em;color:#2467C0\">Descriptive Statistics</h1>\n",
    "\n",
    "Let's look how the ratings are distributed! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .describe method shows summary statistics of the DataFrame, e.g. mean, s.d. etc.\n",
    "# can be used to help figure out if something's wrong with your data - e.g. if max or min values out of the expected range\n",
    "\n",
    "ratings['rating'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['rating'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['rating'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['rating'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['rating'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# .corr method can be used to show correlation between the data using the pairwise Pearson coefficient\n",
    "\n",
    "ratings.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below attempts to create a boolean DataFrame where ratings values are > 5 and assignd to a filter variable\n",
    "# we use the .any method to check if any values exist in the variable - > returns False, which means our ratings data is\n",
    "# in line with what we expect\n",
    "\n",
    "# Pandas any() method is applicable both on Series and DataFrame. It checks whether any value in the caller object \n",
    "# (Dataframe or series) is not 0 and returns True for that. If all values are 0, it will return False\n",
    "\n",
    "filter_1 = ratings['rating'] > 5\n",
    "print(type(filter_1))\n",
    "filter_1.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the .all method can be used on Series or DataFrame as well. It returns whether all elements are True, potentially over an\n",
    "# axis. Returns True unless there at least one element within a series or along a Dataframe axis that is False or\n",
    "# equivalent (e.g. zero or empty)\n",
    "\n",
    "filter_2 = ratings['rating'] > 0\n",
    "filter_2.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:2em;color:#2467C0\">Data Cleaning: Handling Missing Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .shape method yields the number of rows and columns in the DataFrame\n",
    "\n",
    "movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .isnull method detects missing values for an array-like object.\n",
    "\n",
    "# This function takes a scalar or array-like object and indicates whether values are missing (NaN in numeric arrays, None \n",
    "# or NaN in object arrays, NaT in datetimelike). Returns a bool array per each element of data indicating True or False\n",
    "\n",
    "# .any is then run to check if any True values are contained in the bool array -> all False indicits no null values\n",
    "\n",
    "movies.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "That's nice! No NULL values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#is any row NULL ?\n",
    "\n",
    "ratings.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "That's nice! No NULL values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#is any row NULL ?\n",
    "\n",
    "# .isnull() returns some True values in the bool array - and thus .any() returns True for the column in which the True\n",
    "# values were returned (column 'tag' in this case)\n",
    "\n",
    "tags.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We have some tags which are NULL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can then use the .dropna() method to drop the rows which contain null values\n",
    "\n",
    "tags = tags.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking .isnull() again confirms that the null values have been removed\n",
    "\n",
    "tags.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can then rerun the .shape method to compare how many rows remain compared to the original shape. We can see\n",
    "# that only 16 rows have been removed\n",
    "\n",
    "tags.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "That's nice! No NULL values! Notice the number of lines have decreased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:2em;color:#2467C0\">Data Visualization</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas leverages matplotlib underneath for its plotting capabilities\n",
    "\n",
    "# if you want Jupyter to plot the graphs *inside the notebook*, you have to tell Jupyter to plot inline as we see here\n",
    "# (the % symbol before matplotlib below is used for special class functions in Jupyter called 'magic functions')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# .hist method returns a histogram. we need to pass in the data, and figsize to adjust the graph size- can also take other\n",
    "# arguments, e.g. bin size etc.\n",
    "\n",
    "ratings.hist(column='rating', figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .boxplot method takes arguments similar to the .hist method except returns a boxplot rather than histogram\n",
    "\n",
    "ratings.boxplot(column='rating', figsize=(12,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:2em;color:#2467C0\">Slicing Out Columns</h1>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags['tag'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .head method can be performed for multiple columns as below\n",
    "\n",
    "movies[['title','genres']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing rows out of the middle of a DataFrame can be done as below - returns all columns if not specified\n",
    "\n",
    "ratings[1000:1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternatively we can grab from the end as below, etc.\n",
    "\n",
    "ratings[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the .value_counts method counts the number of rows within a given column (e.g. 'tag') per unique name\n",
    "# this can be assigned to a variable, e.g. 'tag_counts' as below\n",
    "\n",
    "tag_counts = tags['tag'].value_counts()\n",
    "tag_counts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_counts[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the assigned cariable can be subsequently plotted as below using the plot function. argument 'kind' specifies\n",
    "# the type of plot you want\n",
    "\n",
    "tag_counts[:10].plot(kind='bar', figsize=(12,9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:2em;color:#2467C0\">Filters for Selecting Rows</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering is a common functionality when you select data that matches a criteria. It is done in 2 steps:\n",
    "# First we need to developt a filter that encodes our criteria (e.g. in to a boolean arrray)\n",
    "# Then we apply that filter as a mask to our DataFrame:\n",
    "\n",
    "# is_highly_rated is the filter which returns a boolean array given the specified criteria\n",
    "is_highly_rated = ratings['rating'] >= 4.0\n",
    "\n",
    "# we then apply the filter to our original DataFrame as a mask, which returns a new array of the filtered data\n",
    "ratings[is_highly_rated][-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below uses the .str.contains method to filter by string - including only genres that contain the word 'animation'. \n",
    "# again, a boolean array is first created with the filter and assigned to variable is_animation\n",
    "# the filter is then assigned (indexed) as a mask to the original DataFrame - and it produces a new DataFrame with the\n",
    "# filtered data\n",
    "\n",
    "is_animation = movies['genres'].str.contains('Animation')\n",
    "\n",
    "movies[is_animation][5:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[is_animation].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:2em;color:#2467C0\">Group By and Aggregate </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregating values across rows gives us a big picture about the whole dataset - so it can be very useful.\n",
    "# we aggregate using the .groupby method.\n",
    "# Once we have performed groupby, and assigned to a variable, we can use other functions such as count or mean to get\n",
    "# the exact statistics we are looking for on the grouped data\n",
    "\n",
    "# the argument in .groupby() is what the grouped data will be indexed by. As example - below uses the count function\n",
    "# on data grouped by rating to work out the number of movies per given rating\n",
    "ratings_count = ratings[['movieId','rating']].groupby('rating').count()\n",
    "ratings_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below groups (indexes) by movieId and calculates the average rating per movie. Note how 'movieId' and 'rating' are first\n",
    "# selected from the ratings DataFrame\n",
    "\n",
    "average_rating = ratings[['movieId','rating']].groupby('movieId').mean()\n",
    "average_rating.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below uses count on the grouped data to work out the number of ratings in our database per movie\n",
    "# as its grouped by 'movieId', this is what it's indexed by\n",
    "\n",
    "movie_count = ratings[['movieId','rating']].groupby('movieId').count()\n",
    "movie_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using .tail we see that some movies only have 1 rating each\n",
    "movie_count.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:2em;color:#2467C0\">Merge Dataframes</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the movies and tags dataframes both have the common column 'movieId' and thus can be inner merged by it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Often when working with Dataframes we need to work with data from multiple frames. A common practice is to want to merge\n",
    "# data we want from multiple frames in to a single frame, and then exeute operations on the new frame. This is similar to \n",
    "# the JOIN operaton in SQL. \n",
    "\n",
    "# the .concat method can be used to stack DataFrames and create a new Dataframe out of them. If a Dataframe is stacked \n",
    "# on to itself, the index for the resulting table will have row indexes from the original table preserved.\n",
    "# If 2 Dataframes given to the cat function havve columns that are separate, the resulting Dataframe will have all columns\n",
    "# from the 2 frames represented -> cells for the columns that didn't exist in the original Dataframe will have NaN values. \n",
    "\n",
    "# if argument join to the .concat method is specified to = 'inner', the 2 Dataframes are placed next to each other\n",
    "# horizontally. This is good except for that columns can be duplicated - e.g. key.\n",
    "\n",
    "# .append method can be used similarly to .concat, as df1.append(df2)  -> appends vertically\n",
    "\n",
    "# To avoid duplicate columns and NaN values, the solution is to use the .merge method. .merge behaves very similarly to\n",
    "# .concat with 'inner' join specified, except that it has the benefit of eliminating duplicate columns. This is very \n",
    "# useful when combining data with the same keys -> similar to working with relational databases\n",
    "\n",
    "# .merge is demonstrated below, joining on 'movieId', specified as an inner join -> Notice how we merge both the tags \n",
    "# data and movies data in to one Dataframe\n",
    "t = movies.merge(tags, on='movieId', how='inner')\n",
    "t.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More examples: http://pandas.pydata.org/pandas-docs/stable/merging.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: Arial; font-size:10; color:#2462C0; font-style:bold\">Combine aggregation, merging, and filters to get useful analytics</h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By setting 'as_index' argument in the .groupby method to False, we ensure that 'movieId' is not the index -> a numerical\n",
    "# index is created to the left of movieId\n",
    "\n",
    "# .mean() is performed on the rating data, and returned per movieId which are grouped in to a single row\n",
    "\n",
    "avg_ratings = ratings.groupby('movieId', as_index=False).mean()\n",
    "del avg_ratings['userId']\n",
    "avg_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can now merge these average ratings (stored in variable avg_ratings) above in to the movies table. As both Dataframes\n",
    "# have the movieId column, this is what we merge on\n",
    "\n",
    "box_office = movies.merge(avg_ratings, on='movieId', how='inner')\n",
    "box_office.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can now apply filters on our merged set of data. remember this is done by creating a boolean array as the filter,\n",
    "# and then apply this as a mask (by indexing) on to the main Dataframe. Our filter below is assigned to variable \n",
    "# 'is_highly_rated' and sets True in the boolean array to movies with a rating >= 4.0\n",
    "\n",
    "is_highly_rated = box_office['rating'] >= 4.0\n",
    "\n",
    "box_office[is_highly_rated][-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarly, we can filter using the .str.contains method to filter by a give string. Again, this returns a boolean array\n",
    "# as a filter which is masked on to the main Dataframe\n",
    "\n",
    "is_comedy = box_office['genres'].str.contains('Comedy')\n",
    "box_office[is_comedy][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, we can apply multiple filters on to our data at the same time. Only values for which are True in both boolean \n",
    "# arrays will be returned below, as we are using the & logical operator \n",
    "\n",
    "# the filter essentially only returns Comedy movings with a high rating\n",
    "\n",
    "box_office[is_comedy & is_highly_rated][-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:2em;color:#2467C0\">Vectorized String Operations</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.35em;color:#2462C0; font-style:bold\"><br>\n",
    "Split 'genres' into multiple columns\n",
    "<br> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the .str.split method will split a string by the given delimiter, and return this as an array of strings (e.g.\n",
    "# a list), rather than just the string itself\n",
    "\n",
    "# if you wish to create new columns in the DataFrame per string split, then you need to set the argument \n",
    "# 'expand' = true in the split method\n",
    "\n",
    "movie_genres = movies['genres'].str.split('|', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_genres[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.35em;color:#2462C0; font-style:bold\"><br>\n",
    "Add a new column for comedy genre flag\n",
    "<br> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the str.contains methdo provides a simple way to check if a string has a given character(s) in it. A boolean series\n",
    "# is returned. \n",
    "\n",
    "# below adds column 'isComedy' to the movie_genres DataFrame which contains a boolean series provided from different\n",
    "# Dataframe, 'movies', indicating whether each genre movie contains 'Comedy' or not \n",
    "\n",
    "movie_genres['isComedy'] = movies['genres'].str.contains('Comedy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_genres[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.35em;color:#2462C0; font-style:bold\"><br>\n",
    "Extract year from title e.g. (1995)\n",
    "<br> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the str.extract method returns the first match for a regular expression (re) it finds. \n",
    "# in below the extracted year string from 'title' is returned in new column 'years' in the movies Dataframe.\n",
    "# with this new years column, data could be grouped by year to gain further insights on the data\n",
    "\n",
    "# re refresher: '\\' preceeding a symbol/character will search for that symbol/character rather than execute its usual\n",
    "# functionality. e.g. in below, '\\(' searches for '(' rather than performing its usual operation of selecting the \n",
    "# data you wish to be extracted. its usual operation is preformed after, ensuring only the information in the parantheses\n",
    "# is extracted (e.g. the year) rather than extracting the parantheses as well\n",
    "\n",
    "movies['year'] = movies['title'].str.extract('.*\\((.*)\\).*', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.35em;color:#2462C0; font-style:bold\"><br>\n",
    "\n",
    "**Further string methods and more info here**: http://pandas.pydata.org/pandas-docs/stable/text.html#text-string-methods\n",
    "<br> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:2em;color:#2467C0\">Parsing Timestamps</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timestamps are common in sensor data or other time series datasets.\n",
    "Let us revisit the *tags.csv* dataset and read the timestamps!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pd.read_csv('./movielens/tags.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note the datatype for our timestamp column is 'int64' - this is the Unix time value\n",
    "\n",
    "tags.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p style=\"font-family: Arial; font-size:1.35em;color:#2462C0; font-style:bold\">\n",
    "\n",
    "Unix time / POSIX time / epoch time records \n",
    "time in seconds <br> since midnight Coordinated Universal Time (UTC) of January 1, 1970\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the .to_datetime method of pandas we are able to convert Unix time into datetime format\n",
    "# (e.g. Datetime64[Ns] or <M8[ns]) -> this presents the date in a human readable format\n",
    "\n",
    "# the unit argument is important here as it tells the method what the unit of the input is\n",
    "\n",
    "# the output below is stored in a new column named 'parsed_time'\n",
    "tags['parsed_time'] = pd.to_datetime(tags['timestamp'], unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.35em;color:#2462C0; font-style:bold\">\n",
    "\n",
    "Data Type datetime64[ns] maps to either <M8[ns] or >M8[ns] depending on the hardware\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tags['parsed_time'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.35em;color:#2462C0; font-style:bold\">\n",
    "\n",
    "Selecting rows based on timestamps\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that the time is converted to Python format, we can use it to create filters. As with \n",
    "# other filters we've created, we assign a variable to the filter which returns a boolean array.\n",
    "# the boolean array is then masked on to our data to return a filtered set of the original data\n",
    "# according to the criteria set in our filter\n",
    "\n",
    "# below only returns data in our Dataframe from after 1 Feb 2015\n",
    "greater_than_t = tags['parsed_time'] > '2015-02-01'\n",
    "\n",
    "selected_rows = tags[greater_than_t]\n",
    "\n",
    "# by comparing the shape of our original data with our filtered data, we can see that only\n",
    "# approx 15k/465k lines of data are from after 2 Feb 2015\n",
    "tags.shape, selected_rows.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.35em;color:#2462C0; font-style:bold\">\n",
    "\n",
    "Sorting the table using the timestamps\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the .sort_values method we can then sort our timeseries data by the timestamps, either\n",
    "# ascending (from the beginning of time) or descending (from the end of time going backwards)\n",
    "\n",
    "# below displays the first 10 datapoints of our dataset - we see the original data started in 2005\n",
    "tags.sort_values(by='parsed_time', ascending=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:2em;color:#2467C0\">Average Movie Ratings over Time</h1>\n",
    "\n",
    "## Are Movie Ratings related to the Year of Launch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to answer this question, we first yield the average rating per each of our movies - this is \n",
    "# done by using the .groupby method to group the movieId's per rating, and then taking the mean \n",
    "# rating of each movie. this is then stored in a new array named average_rating\n",
    "\n",
    "average_rating = ratings[['movieId','rating']].groupby('movieId', as_index=False).mean()\n",
    "average_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the average_rating array is then joined with the movies array by movieId. this adds on \n",
    "# the extra column 'rating' to the movies array which contains the average rating per movie\n",
    "\n",
    "joined = movies.merge(average_rating, on='movieId', how='inner')\n",
    "joined.head()\n",
    "# joined.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to yield average rating per year we create a new array named yearly_average which is created\n",
    "# using the 'year' & 'rating' columns from our joined table. this is grouped by year and paired\n",
    "# against the mean of each rating per year\n",
    "\n",
    "yearly_average = joined[['year','rating']].groupby('year', as_index=False).mean()\n",
    "yearly_average[-15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can now plot these results below for the most recent 20 years of our data using the .plot\n",
    "# method\n",
    "\n",
    "# notice how after 2009 there is a spike in rating. this is likely an outlier or error in our\n",
    "# data and requires further investigation. On further invesigation - we can see that year\n",
    "# \"2009-\" comes after 2009, and it has 1 rating of 5 stars. this is what's causing the spike. \n",
    "# to fix this we need to clean the data and amend \"2009-\" to 2009.\n",
    "\n",
    "yearly_average[-20:].plot(x='year', y='rating', figsize=(15,10), grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.35em;color:#2462C0; font-style:bold\">\n",
    "Do some years look better for the box office movies than others? <br><br>\n",
    "Does any data point seem like an outlier in some sense?\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above are examples of questions we can ask when analysing the plot of our data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
